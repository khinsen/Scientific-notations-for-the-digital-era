\section{The state of the art in managing digital scientific knowledge}
\label{state-of-the-art}

In the last section I have listed the ingredients that need to be combined in order to make a solar system simulator. Let's look at how such a simulator is actually structured using today's scientific computing technology. We have the following clearly identifiable pieces:

\begin{enumerate}
\item A simulation program, written in a programming language such as Fortran or C++, which incorporates ingredients 1, 2, 5, 7, and 8.
\item An input file for that program, written in a special-purpose formal language defined by the author of the simulation program, containing ingredients 3, 4, and 6.
\end{enumerate}

The structure of the input file is usually simple, meaning that it is straightforward to isolate ingredients 3, 4, and 6 from it. There is even a good chance that the input file will permit annotation of these items, indicating the sources they were taken from. If we are really lucky, the formal language of the input file is documented and designed to permit the extraction of information for other uses.

The simulation program itself is almost certainly a monolithic piece of information that combines 1, 2, 5, 7, and 8 in an inextricable way. None of the ingredients is easy to identify by inspection, and we'd better not even envisage extracting them using computational tools for other uses. If we want to change something, e.g. use a different ODE solver or a different finite-size number representation, we'd probably rewrite large parts of the program from scratch. Worse, changing the finite-size number representation might actually force us to rewrite the program in a different language.

This is how today's scientific software is typically written, but let's also look at what we \textit{could} do, using today's technology, if we were making a special effort to maintain the modular structure of our knowledge assembly.

The easiest part to factor out is number 5, the ODE solver. We could use one from a program library, and even choose a library that proposes several solvers. But using such a library comes at an additional cost in combining all the parts. We have to write ingredients 1 and 2 according to the rules of the library, and accept for 7 and 8 whatever the library allows us to use. In fact, the library modifies the formal language we use for writing our software, adding features but also imposing constraints. Fortran plus ODEPACK is not the same language as Fortran on its own.

Superficially, we can also factor out ingredients 1 and 2, which define the equations fed to the ODE solver. We could isolate these ingredients in the form of procedures (also called subroutines or functions). But those procedures do \textit{not} represent the original equations. They only represent one aspect of the equations: the numerical evaluation of some of their subterms. We could not use these procedures to prove energy conservation, nor to derive Kepler's laws.

Finally, we could envisage factoring out ingredient 7, the number representation. For example, we could use a library such as MPFR \cite{fousse_mpfr_2007} to get access to wide range of floating-point formats. But the same remark applies as for the use of an ODE library: we would have to translate everything else into the C + MPFR language with its rather peculiar requirements. Moreover, it's either MPFR or an ODE library, unless we can find an ODE library written specifically for use with MPFR. The reason why can't freely combine an ODE library with a finite-size arithmetic library is the same that prevents us from using the ODE-specific equation-evaluation procedures for other purposes: an ODE library does not contain ODE solver algorithms, but specific \textit{implementations} of such algorithms that are less versatile than the algorithms themselves.

Leaving the narrow realm of development tools for numerical software, we could try to factor out the equations, ingredients 1 and 2, using a computer algebra system. Such a system lets us write down the equations as such, not only the numerical computation of its subterms. While the idea looks promising, the state of today's computer algebra systems doesn't make this a practically useful approach. They are not designed as parts of an ecosystem for scientific knowledge management. The formal languages they use for expressing terms and equations are insufficiently documented, and for commercial systems they are even partly secret. Some computer algebra systems have export functions that generate numerical code in a language like C or Fortran, but the exact semantics of this export are again opaque for lack of documentation.

\subsection{Complex systems}
\label{complex-systems}

For the example I have used in the last section, there is no real problem in practice because the whole model is rather simple. Ingredients 1 to 7 can be written down and composed on a single sheet of paper. We use computers only because the actual computation is very long to perform. It is quite feasible to do all theroretical work by hand, and write a simulation program just for doing the computation. That was in fact the dominant use of computers in science during their first few decades.

The situation changes drastically when we consider complex systems. If instead of the solar system we wish to simulate a protein at the atomic scale, we use a model that is overall very similar except for the second ingredient. Instead of Newton's law of gravitation, a one-line formula, we have an expression for the interatomic forces made up of tens of thousands of terms. The list of these terms is constructed from the molecular structure by an algorithm, meaning that we need a computer -- and thus formal languages -- not only for \textit{simulating} our model but already for \textit{defining} it. The model itself is digital scientific knowledge.

Since we do not have adequate formal languages for writing down such digital models today, we cannot express them at all. We cannot analyze or discuss the model, nor compare it in depth to competing models. All we have is research papers describing the design principles behind the model, and software written to perform a numerical evaluation. The software source code is impenetrable for anyone but its authors. Moreover, there is obviously no way to verify that the software evaluates the model correctly, because that would require some other expression of the model for comparison. This is again an instance of the problem that I discussed earlier (section~\ref{formal-languages}) for the definition of the semantics of programming languages. Our model should be part of the \textit{specification} of our software, rather than being completely absorbed into its source code.

In the case of the popular models for biomolecular simulations, each of them is implemented by several different software packages, with each program producing somewhat different numbers for the same protein. On a closer look, each program actually implements its own variation of the model, with modifications made for performance reasons, or because the software authors believe the modification to be an improvement. In the end, what we think of as a model is really a family of different models derived from common design principles. In the absence of human-readable specifications of each variant, we cannot compile a detailed list of the differences, let alone estimate their impact on the results we obtain.

Similar situations exist wherever scientific models have become too complex to be written down on paper. As a second example, consider the Community Earth System Model \cite{_community_1983}, a popular model for the evolution of the Earth's climate. One would expect such a model to consist of a large number of coupled partial differential equations describing the behavior of the atmosphere and the oceans, and their complex interactions. But it really is a software package that implements a numerical solver for the equations. Contrary to the situation in biomolecular simulation, a significant effort is made to ensure that this software package can be considered a reliable reference implementation. But even if we trust the software to reliably evaluate the model numerically, we have still lost all the non-numerical uses of a scientific model.

\subsection{Software and data in computational science}
\label{software-data}

It is customary in computational science to distinguish between computer programs, also called \textit{software}, and the \textit{data} that these programs process. But the above discussion of formal languages shows that this distinction between software and data is not fundamental. We could very well use a single language to define all aspects of a computation, and obtain the result in the same language. This is in fact very easy to do, by hard-coding all input data into the source code of the program. In today's computing environments, that would be inconvenient in practice, but that is mostly due to the way our tools work.

From the point of view of digital knowledgement management, it is desirable to identify the individual pieces of information we wish to handle, and the operations we wish to perform on them. The above analysis of a solar system simulation provides a simple example. We would then design formal languages specifically as digital scientific notations for our knowledge items. Software tools would be just tools, consuming and transforming scientific knowledge but not absorbing it into its source code. In other words, all scientific knowledge would become \textit{data}.

Some recent developments can be seen as stepping stones towards this goal. I will mention a single example, the specification of differential equations in FEniCS \cite{alnaes_fenics_2015}. FEniCS is a software package that solves partial differential equations numerically using the Finite Element method. A feature that distinguishes FEniCS from similar software packages is that it allows its users to write the differential equations to be solved in a notation very similar to traditional mathematics. In particular, the equations are written down as distinct information items, i.e. they are \textit{data}. They are \textit{not} absorbed into program code that is structured according to the needs of software development. Similar approaches are used in other mathematical software packages. However, a crucial final step remains to be taken: Differential equations for FEniCS are written in a FEniCS-specific formal language that is not suitable for anything else than solving the equations in FEniCS. The scientific knowledge must be reformulated to fit to the tool. What we should have instead is a formal language for expressing all aspects of differential equations, and many tools, FEniCS being just one of them, that can process this formal language. In particular, we would like to be able to \textit{compose} differential equations describing some physical system from individual ingredients, much like the equations governing the solar system are composed from the law of motion and the law of gravity.

One psychological barrier to considering all scientific knowledge as data is the fact that scientific knowledge includes algorithms. In the example of the solar system simulation, the numerical method for solving Newton's equation is an algorithm. The formal languages used to represent data in computational science do not permit the expression of algorithms. For most computational scientists, algorithms are parts of programs, and thus expressed in a programming language. However, it is easy to see that algorithms are just another kind of data. Compilers translate algorithms from one formal language to another, i.e. they process algorithms as data. The same can be said of many tools we use every day to develop and analyze software. The only novelty in my proposal is that algorithms that count as scientific knowledge should be available for all kinds of scrutiny \textit{in addition} to being executable by a computer.

We can also envisage an intermediate stage in which software tools continue to incorporate digital scientific knowledge just like they do today, but in which we also express and publish all digital scientific knowledge in human-friendly formal languages. The human-friendly version would then be part of the software's specification, and the equivalence of the two formulations would be verified as part of software testing.
